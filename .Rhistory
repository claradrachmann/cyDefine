compensate = FALSE,         # Compensation for spectral overlap, only for flow
extract_filename_regex = "\\d{2}Feb18_Helios2_(Plate\\d+)_(Sample\\d+)_HIMCctrl_(.+)$",
extract_filename_into = c("batch", "sample", "celltype"))
unique(reference$celltype)
reference
classified_query <- classify_cells(reference = reference,
query = query,
markers = markers,
load_model = "../example_data/example_model.RDS",
seed = 332)
# Markers of interest
markers <- c('CD16', 'CD26', 'CD8a', 'CD33', 'CD161', 'CCR10', 'CCR7', 'CCR9',
'CD3', 'ICOS', 'CD45RA', 'CD27', 'CXCR3', 'NKG2A', 'CD14', 'CD127',
'CD57', 'HLADR', 'CD62L', 'CD19', 'IgG', 'CD4', 'IgD', 'IgA',
'CD86', 'CD45BC2', 'CD45BC3', 'CD45BC4', 'CD45BC5', 'CCR6', 'CD20',
'CD56', 'TCRgd', 'CD123', 'CD11c', 'CD25', 'CD45BC1', 'CXCR5',
'CD38', 'a4b7', 'PD1', 'CLA')
classified_query <- classify_cells(reference = reference,
query = query,
markers = markers,
load_model = "../example_data/example_model.RDS",
seed = 332)
# Markers of interest
markers <- c('CD16', 'CD26', 'CD8a', 'CD33', 'CD161', 'CCR10', 'CCR7', 'CCR9',
'CD3', 'ICOS', 'CD45RA', 'CD27', 'CXCR3', 'NKG2A', 'CD14', 'CD127',
'CD57', 'HLADR', 'CD62L', 'CD19', 'IgG', 'CD4', 'IgD', 'IgA',
'CD86', 'CCR6', 'CD20', 'CD56', 'TCRgd', 'CD123', 'CD11c', 'CD25',
'CXCR5', 'CD38', 'a4b7', 'PD1', 'CLA')
classified_query <- classify_cells(reference = reference,
query = query,
markers = markers,
load_model = "../example_data/example_model.RDS",
seed = 332)
# Prepare reference tibble from directory of FCS files
query <- prepare_data(
data_dir = system.file("extdata", package = "cyDefine", mustWork = TRUE),
pattern = "Plate4_Sample1", # Using Sample1 from Plate4 as query
markers = markers,
transform = TRUE,         # ArcSinh transformation
cofactor = 5,             # CyTOF: 5, flow cytometry: 150, spectral: 6000
derand = TRUE,            # Derandomization, only for CyTOF
compensate = FALSE,       # Compensation for spectral overlap, only for flow
extract_filename_regex = "^\\d{2}Feb18_Helios2_(Plate\\d+)_(Sample\\d+)",
extract_filename_into = c("batch", "sample"))
classified_query <- classify_cells(reference = reference,
query = query,
markers = markers,
load_model = "../example_data/example_model.RDS",
seed = 332)
#' @param n_trees Number of trees in the random forest
#' @param seed Random seed
#' @param n_cores The number of cores to use for parallel execution. Obs:
#' parallel execution only performed if the 'doParallel' package is installed!
#' @param verbose Verbosity
#'
#' @return Tibble of query data with an added column of the predicted cell type, 'model_prediction'
#' @export
#'
#' @examples
classify_cells <- function(reference,
query,
markers,
unassigned_name = "unassigned",
load_model = NULL,
save_model = NULL,
return_pred = FALSE,
n_cv_folds = 5,
n_trees = 100,
seed = 332,
n_cores = 2,
verbose = TRUE) {
check_colnames(colnames(reference), c("celltype", markers))
check_colnames(colnames(query), c(markers))
# remove unassigned cells from reference prior to classification
reference <- reference %>%
dplyr::filter(celltype != !!unassigned_name)
# keep track of ids
if ("id" %!in% colnames(query)) {query$id <- 1:nrow(query)}
if (!is.null(load_model)) {
if (verbose) {message("Loading saved model: ", load_model)}
rf_model <- readRDS(file = load_model)
}
else {
# stratified cross-validation
set.seed(seed)
train_control <- caret::trainControl(method = "cv",
number = n_cv_folds,
summaryFunction = macroF1_summary,
preProcOptions = c("center", "scale"),
allowParallel = TRUE)
param_grid <- expand.grid(mtry = as.integer(seq(from = round(0.25*length(markers)),
to = round(0.9*length(markers)),
length.out = 8)),
min.node.size = seq(1, 6, 2),
splitrule = "gini")
if (verbose) {message("Training random forest using ", n_cv_folds,
"-fold cross-validation for tuning hyperparameters")}
model_weights <- reference %>%
dplyr::group_by(celltype) %>%
dplyr::mutate(weight = nrow(reference)/dplyr::n()) %>%
dplyr::ungroup() %>%
dplyr::mutate(weight = weight/sum(weight)) %>%
dplyr::pull(weight)
# enable parallel computation
if (check_package("doParallel", required = FALSE)) {
doParallel::registerDoParallel(cores = n_cores)
if (verbose) {message("Number of parallel workers: ",
foreach::getDoParWorkers())}
}
else {
if (verbose) {message("Package doParallel is not installed. ",
"Continuing without parallellization")}
}
rf_model <- caret::train(x = as.data.frame(reference[, markers]),
y = factor(reference$celltype),
weights = model_weights,
method = 'ranger',
trControl = train_control,
tuneGrid = param_grid,
metric = "macroF1",
num.trees = n_trees,
importance = "impurity",
oob.error = FALSE)
# stop parallel computing
if (check_package("doParallel", required = FALSE)) {
doParallel::stopImplicitCluster()
}
if (verbose) {message("Optimal model parameters selected to be:\n  ",
paste(names(rf_model$bestTune),
rf_model$bestTune,
sep = ": ",
collapse = "\n  "))}
# save model
if (!is.null(save_model)) {saveRDS(object = rf_model, file = save_model)}
}
pred <- predict(object = rf_model,
newdata = query[, markers])
if (return_pred) {return (pred)}
# add model predictions to query
query <- dplyr::bind_cols(query, "model_prediction" = pred)
return (query %>% dplyr::arrange(id))
}
classified_query <- classify_cells(reference = reference,
query = query,
markers = markers,
load_model = "../example_data/example_model.RDS",
seed = 332)
classified_query <- classify_cells(reference = reference,
query = query,
markers = markers,
load_model = "../../../cyDefine/example_data/example_model.RDS",
seed = 332)
classified_query <- classify_cells(reference = reference,
query = query,
markers = markers,
load_model = "../../../cyDefine/data/example_model.RDS",
seed = 332)
classified_query <- classify_cells(reference = reference,
query = query,
markers = markers,
load_model = "../../../cyDefine/data/example_model.rda",
seed = 332)
#' @param n_trees Number of trees in the random forest
#' @param seed Random seed
#' @param n_cores The number of cores to use for parallel execution. Obs:
#' parallel execution only performed if the 'doParallel' package is installed!
#' @param verbose Verbosity
#'
#' @return Tibble of query data with an added column of the predicted cell type, 'model_prediction'
#' @export
#'
#' @examples
classify_cells <- function(reference,
query,
markers,
unassigned_name = "unassigned",
load_model = NULL,
save_model = NULL,
return_pred = FALSE,
n_cv_folds = 5,
n_trees = 100,
seed = 332,
n_cores = 2,
verbose = TRUE) {
check_colnames(colnames(reference), c("celltype", markers))
check_colnames(colnames(query), c(markers))
# remove unassigned cells from reference prior to classification
reference <- reference %>%
dplyr::filter(celltype != !!unassigned_name)
# keep track of ids
if ("id" %!in% colnames(query)) {query$id <- 1:nrow(query)}
if (!is.null(load_model)) {
if (verbose) {message("Loading saved model: ", load_model)}
rf_model <- read(load_model)
}
else {
# stratified cross-validation
set.seed(seed)
train_control <- caret::trainControl(method = "cv",
number = n_cv_folds,
summaryFunction = macroF1_summary,
preProcOptions = c("center", "scale"),
allowParallel = TRUE)
param_grid <- expand.grid(mtry = as.integer(seq(from = round(0.25*length(markers)),
to = round(0.9*length(markers)),
length.out = 8)),
min.node.size = seq(1, 6, 2),
splitrule = "gini")
if (verbose) {message("Training random forest using ", n_cv_folds,
"-fold cross-validation for tuning hyperparameters")}
model_weights <- reference %>%
dplyr::group_by(celltype) %>%
dplyr::mutate(weight = nrow(reference)/dplyr::n()) %>%
dplyr::ungroup() %>%
dplyr::mutate(weight = weight/sum(weight)) %>%
dplyr::pull(weight)
# enable parallel computation
if (check_package("doParallel", required = FALSE)) {
doParallel::registerDoParallel(cores = n_cores)
if (verbose) {message("Number of parallel workers: ",
foreach::getDoParWorkers())}
}
else {
if (verbose) {message("Package doParallel is not installed. ",
"Continuing without parallellization")}
}
rf_model <- caret::train(x = as.data.frame(reference[, markers]),
y = factor(reference$celltype),
weights = model_weights,
method = 'ranger',
trControl = train_control,
tuneGrid = param_grid,
metric = "macroF1",
num.trees = n_trees,
importance = "impurity",
oob.error = FALSE)
# stop parallel computing
if (check_package("doParallel", required = FALSE)) {
doParallel::stopImplicitCluster()
}
if (verbose) {message("Optimal model parameters selected to be:\n  ",
paste(names(rf_model$bestTune),
rf_model$bestTune,
sep = ": ",
collapse = "\n  "))}
# save model
if (!is.null(save_model)) {save(rf_model, file = save_model)}
}
pred <- predict(object = rf_model,
newdata = query[, markers])
if (return_pred) {return (pred)}
# add model predictions to query
query <- dplyr::bind_cols(query, "model_prediction" = pred)
return (query %>% dplyr::arrange(id))
}
classified_query <- classify_cells(reference = reference,
query = query,
markers = markers,
load_model = "../data/example_model.rda",
seed = 332)
classified_query <- classify_cells(reference = reference,
query = query,
markers = markers,
load_model = "../data/example_model.rda",
seed = 332)
#' @param n_trees Number of trees in the random forest
#' @param seed Random seed
#' @param n_cores The number of cores to use for parallel execution. Obs:
#' parallel execution only performed if the 'doParallel' package is installed!
#' @param verbose Verbosity
#'
#' @return Tibble of query data with an added column of the predicted cell type, 'model_prediction'
#' @export
#'
#' @examples
classify_cells <- function(reference,
query,
markers,
unassigned_name = "unassigned",
load_model = NULL,
save_model = NULL,
return_pred = FALSE,
n_cv_folds = 5,
n_trees = 100,
seed = 332,
n_cores = 2,
verbose = TRUE) {
check_colnames(colnames(reference), c("celltype", markers))
check_colnames(colnames(query), c(markers))
# remove unassigned cells from reference prior to classification
reference <- reference %>%
dplyr::filter(celltype != !!unassigned_name)
# keep track of ids
if ("id" %!in% colnames(query)) {query$id <- 1:nrow(query)}
if (!is.null(load_model)) {
if (verbose) {message("Loading saved model: ", load_model)}
rf_model <- load(load_model)
}
else {
# stratified cross-validation
set.seed(seed)
train_control <- caret::trainControl(method = "cv",
number = n_cv_folds,
summaryFunction = macroF1_summary,
preProcOptions = c("center", "scale"),
allowParallel = TRUE)
param_grid <- expand.grid(mtry = as.integer(seq(from = round(0.25*length(markers)),
to = round(0.9*length(markers)),
length.out = 8)),
min.node.size = seq(1, 6, 2),
splitrule = "gini")
if (verbose) {message("Training random forest using ", n_cv_folds,
"-fold cross-validation for tuning hyperparameters")}
model_weights <- reference %>%
dplyr::group_by(celltype) %>%
dplyr::mutate(weight = nrow(reference)/dplyr::n()) %>%
dplyr::ungroup() %>%
dplyr::mutate(weight = weight/sum(weight)) %>%
dplyr::pull(weight)
# enable parallel computation
if (check_package("doParallel", required = FALSE)) {
doParallel::registerDoParallel(cores = n_cores)
if (verbose) {message("Number of parallel workers: ",
foreach::getDoParWorkers())}
}
else {
if (verbose) {message("Package doParallel is not installed. ",
"Continuing without parallellization")}
}
rf_model <- caret::train(x = as.data.frame(reference[, markers]),
y = factor(reference$celltype),
weights = model_weights,
method = 'ranger',
trControl = train_control,
tuneGrid = param_grid,
metric = "macroF1",
num.trees = n_trees,
importance = "impurity",
oob.error = FALSE)
# stop parallel computing
if (check_package("doParallel", required = FALSE)) {
doParallel::stopImplicitCluster()
}
if (verbose) {message("Optimal model parameters selected to be:\n  ",
paste(names(rf_model$bestTune),
rf_model$bestTune,
sep = ": ",
collapse = "\n  "))}
# save model
if (!is.null(save_model)) {save(rf_model, file = save_model)}
}
pred <- predict(object = rf_model,
newdata = query[, markers])
if (return_pred) {return (pred)}
# add model predictions to query
query <- dplyr::bind_cols(query, "model_prediction" = pred)
return (query %>% dplyr::arrange(id))
}
classified_query <- classify_cells(reference = reference,
query = query,
markers = markers,
load_model = "../data/example_model.rda",
seed = 332)
query
getwd()
classified_query <- classify_cells(reference = reference,
query = query,
markers = markers,
load_model = "../../../cyDefine/data/example_model.rda",
seed = 332)
classified_query <- classify_cells(reference = reference,
query = query,
markers = markers,
load_model = "../data/example_model.rda",
seed = 332)
getwd()
classified_query <- classify_cells(reference = reference,
query = query,
markers = markers,
load_model = "../../../cyDefine/data/example_model.rda",
seed = 332)
load_model = "../../../cyDefine/data/example_model.rda"
"id" %!in% colnames(query)
rf_model <- load(load_model)
rf_model
getwd()
classified_query <- classify_cells(reference = reference,
query = query,
markers = markers,
save_model = "../data/example_model.rda",
seed = 332)
load("../data/example_model.rda")
load("../data/example_model.rda")
rf_model
rm(rf_model)
load("../data/example_model.rda")
load("../data/example_model.rda")
rf_model
knitr::opts_chunk$set(
strip.white = T,
comment = ""
)
library(tidyverse)
devtools::load_all()
# Markers of interest
markers <- c('CD16', 'CD26', 'CD8a', 'CD33', 'CD161', 'CCR10', 'CCR7', 'CCR9',
'CD3', 'ICOS', 'CD45RA', 'CD27', 'CXCR3', 'NKG2A', 'CD14', 'CD127',
'CD57', 'HLADR', 'CD62L', 'CD19', 'IgG', 'CD4', 'IgD', 'IgA',
'CD86', 'CCR6', 'CD20', 'CD56', 'TCRgd', 'CD123', 'CD11c', 'CD25',
'CXCR5', 'CD38', 'a4b7', 'PD1', 'CLA')
# Prepare reference tibble from directory of FCS files
reference <- prepare_data(
data_dir = system.file("extdata", package = "cyDefine", mustWork = TRUE),
pattern = "Plate3_Sample1", # Using Sample1 from Plate3 as reference
markers = markers,
transform = TRUE,           # ArcSinh transformation
cofactor = 5,               # CyTOF: 5, flow cytometry: 150, spectral: 6000
derand = TRUE,              # Derandomization, only for CyTOF
compensate = FALSE,         # Compensation for spectral overlap, only for flow
extract_filename_regex = "\\d{2}Feb18_Helios2_(Plate\\d+)_(Sample\\d+)_HIMCctrl_(.+)$",
extract_filename_into = c("batch", "sample", "celltype"))
# Prepare reference tibble from directory of FCS files
query <- prepare_data(
data_dir = system.file("extdata", package = "cyDefine", mustWork = TRUE),
pattern = "Plate4_Sample1", # Using Sample1 from Plate4 as query
markers = markers,
transform = TRUE,         # ArcSinh transformation
cofactor = 5,             # CyTOF: 5, flow cytometry: 150, spectral: 6000
derand = TRUE,            # Derandomization, only for CyTOF
compensate = FALSE,       # Compensation for spectral overlap, only for flow
extract_filename_regex = "^\\d{2}Feb18_Helios2_(Plate\\d+)_(Sample\\d+)",
extract_filename_into = c("batch", "sample"))
unassigned_names <- c("Non-pDC-non-mDC", "NonNK-nonDC")
# rename cell types
reference <- reference %>%
mutate(celltype = replace(celltype,
celltype %in% unassigned_names,
"unassigned"))
# Markers of interest
markers <- c('CD16', 'CD26', 'CD8a', 'CD33', 'CD161', 'CCR10', 'CCR7', 'CCR9',
'CD3', 'ICOS', 'CD45RA', 'CD27', 'CXCR3', 'NKG2A', 'CD14', 'CD127',
'CD57', 'HLADR', 'CD62L', 'CD19', 'IgG', 'CD4', 'IgD', 'IgA',
'CD86', 'CCR6', 'CD20', 'CD56', 'TCRgd', 'CD123', 'CD11c', 'CD25',
'CXCR5', 'CD38', 'a4b7', 'PD1', 'CLA')
# Prepare tibbles
reference <- read_csv("reference.csv")
corrected <- batch_correct(reference,
query,
markers,
norm_method = "scale",  # "rank" recommended for heavy batch effects (e.g. different technologies)
covar = NULL,
seed = 332)
reference <- corrected$reference
query <- corrected$query
classified_query <- classify_cells(reference = reference,
query = query,
markers = markers,
load_model = load("../data/example_model.rda"),
seed = 332)
rmarkdown::render('cyDefine_custom.Rmd')
rmarkdown::render('vignettes/cyDefine_custom.Rmd')
getwd()
rmarkdown::render('../../../cyDefine/vignettes/cyDefine_custom.Rmd')
setwd("../../../cyDefine/")
rm(rf_model)
load("data/example_model.rda")
rf_model
rmarkdown::render('vignettes/cyDefine_custom.Rmd')
lookup <- list("donor1" = list("A" = c("A0201", "A1101"), "B" = c("B3501", "UNKNOWN")),
"donor2" = list("A" = c("A0201", "A0101"), "B" = c("B0801", "UNKNOWN")),
"donor3" = list("A" = c("A2402", "A2902"), "B" = c("B3502", "B4403")),
"donor4" = list("A" = c("A0301", "A0301"), "B" = c("B0702", "B5701")))
lookup
.data <- tibble(donor = c("donor1", "donor2", "donor1", "donor3", "donor3", "donor4"),
allele = c("A0301", "A2402", "A0301", "A0301", "B0702", "B5701"))
.data
library(tidyverse)
.data <- tibble(donor = c("donor1", "donor2", "donor1", "donor3", "donor3", "donor4"),
allele = c("A0301", "A2402", "A0301", "A0301", "B0702", "B5701"))
.data
.data %>%
dplyr::mutate(HLA_match = dplyr::case_when(allele %in% lookup[[donor]][["A"]] ~ "TRUE",
allele %in% lookup[[donor]][["B"]] ~ "TRUE"))
.data
lookup <- list("donor1" = list("A" = c("A0201", "A1101"), "B" = c("B3501")),
"donor2" = list("A" = c("A0201", "A0101"), "B" = c("B0801")),
"donor3" = list("A" = c("A2402", "A2902"), "B" = c("B3502", "B4403")),
"donor4" = list("A" = c("A0301", "A0301"), "B" = c("B0702", "B5701")))
data <- tibble(donor = c("donor1", "donor2", "donor1", "donor3", "donor3", "donor4"),
allele = c("A0301", "A2402", "A0301", "A0301", "B0702", "B5701"))
data %>%
dplyr::mutate(HLA_match = dplyr::case_when(allele %in% lookup[[donor]][["A"]] ~ TRUE,
allele %in% lookup[[donor]][["B"]] ~ TRUE,
TRUE ~ FALSE))
lookup
tibble(lookup)
as_tibble(lookup)
data %>%
dplyr::mutate(HLA_match = dplyr::case_when(allele %in% as_tibble(lookup)[[donor]][["A"]] ~ TRUE,
allele %in% as_tibble(lookup)[[donor]][["B"]] ~ TRUE,
TRUE ~ FALSE))
data %>%
rowwise() %>%
dplyr::mutate(HLA_match = dplyr::case_when(allele %in% lookup[[donor]][["A"]] ~ TRUE,
allele %in% lookup[[donor]][["B"]] ~ TRUE,
TRUE ~ FALSE))
data %>%
rowwise() %>%
dplyr::mutate(HLA_match = dplyr::case_when(allele %in% lookup[[donor]][["A"]] ~ TRUE,
allele %in% lookup[[donor]][["B"]] ~ TRUE,
TRUE ~ FALSE)) %>%
ungroup()
